Bei machine learning Aufgaben geht man davon aus, dass die beschrifteten, primären Trainingsdaten den Testdaten ähnlich sind, um eine gute Genauigkeit auf den Testdaten zu erwarten. Desweiteren ist es wichtig, Trainingsdaten in beträchtlicher Menge zu haben, um ein zuverlässiges Modell für Klassifikation zu erstellen. Während es in der Anwendung zwar für gewöhnlich zeitaufwändig und teuer ist, beschriftete Instanzen zu erhalten, die den Testdaten ähnlich sind, haben wir möglicherweise oft reichlich beschriftete Daten einer Hilfsquelle, die sich etwas von unseren Testdaten unterscheidet. Trotz diesem Unterschieden im Großen und Ganzen zwischen den Datensätzen, gibt es möglicherweise Teile aus den Hilfsdaten, die ähnlich und daher nützlich sind. Genauer gesagt untersuchen wir hier Algorithmen, die auf der Annahme aufbauen, dass die Verteilung der Hilfsdaten ein Mix zwischen der Verteilung der Hauptdaten und einer anderen Verteilung ist. Bei NLP (natural language processing = Verarbeitung natürliches Sprache) Aufgaben wie etwa Eigennamenerkennung, Satzanalyse, Textklassifizierung, etc. haben wir normalerweise reichlich Daten von Standardtextkörpern aber wenig Daten für speziellere Textgenres, an deren Verarbeitung wir interessiert sind. In benutzerzentrierten Aufgaben, wie etwa Spamerkennung, Handschrift-/Stimmenerkennung, etc. gibt es für gewöhnlich nur wenig beschriftete Daten je individuellem Benutzer der das System verwendet, während es große Mengen an beschrifteten Daten für die Gesamtheit der Nutzer gibt. Ein domänenanpassungs Lernrahmen beinhaltet eine Hauptdomäne D_P und eine Hilfsdomäne D_A. Wir beschäftigen uns hauptsächlich mit dem Problem des Lernens mit zwei Domänen, obwohl es möglich ist, zur Behandlung von mehreren Domänen zu generalisieren. Wir bezeichnen die Datensätze, die wir stichprobenartig aus der Haupt- und Hilfsdomäne ziehen als (x_1^p, y_1^p), ..., (x_{N_P}^p, y_{N_P}^p) und ... wobei N_P und N_A die Stichprobengrößen von jeweils des Haupt- und  Hilfsdatensatzes darstellen. Ein Lernalgorithmus nimmt beschriftete Trainingsinstanzen stichprobenartig aus den zwei Domänen und schätzt eine Beschriftungsfunktion für die Hauptdomäne ab. Der Testdatensatz zur Auswertung des Lernalgorithmus wird aus der Hauptdomäne gezogen. Das zentrale Problem eines solchen Lernrahmens ist, dass wir nur wenige Haupttrainingsinstanzen und relativ zahlreiche Hilfstrainingsinstanzen haben. Den beschrifteten Hauptinstanzen kann man hohe Kosten zuschreiben, im Gegensatz zu den Hilfsinstanzen, die niedrige Kosten haben. Wennn wir schon  eine große Mengen an Hauptinstanzen hätten, könnten wir das Lernen gut genug mit standardmäßigen, überwachten Lernmethoden durchführen und bräuchten keine Hilfsdaten. Da es schwierig ist, mit einem kleinen Hauptdatensatz eine gute Beschriftungsfunktion zu erhalten, zielen wir darauf ab, zum Lernen Hilfsdaten zu verwenden. Tatsächlich ist Situationen zu identifizieren, in denen es dem Training hilft, Hilfsdaten zusammen mit den Hauptdaten zu verwenden, eine grundlegende Frage, die wir in dieser Arbeit versuchen zu beantworten.
