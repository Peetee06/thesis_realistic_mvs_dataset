\chapter{Experiments}
\label{sec:experiments}

In this chapter the three Domain Adaptation Techniques \textit{Cycle-consistent Generative Adversarial Network} \cite{DBLP:journals/corr/ZhuPIE17}, \textit{Cycle Consistent Adversarial Domain Adaptation} \cite{DBLP:journals/corr/abs-1711-03213} and \textit{Semantic-aware Grad-GAN for Virtual-to-Real Urban Scene Adaption} \cite{DBLP:journals/corr/abs-1801-01726} will be compared by analysing similarities and differences. Furthermore pretrained models of each architecture were used to generate translated images on which a pretrained deeplabv3 model then was used to perform semantic segmentation and the results will be compared on their Intersection over Union scores.

%\section{training the nets on tcml cluster} \todo{is this necessary or can we just use provided pre-trained models?}
%To train the models the tcml cluster of uni t√ºbingen was used (\todo{add link to cluster website}). The cluster contains a lot of computing power with multiple compute nodes and a storage node. Each compute node has 4 CPUs and a NVidia 1080 Ti GPU and lots of RAM. In order to run the training code, it is necessary to create an .sbatch file. This file specifies how long a script needs to run, how much memory it needs and includes bash commands to run the script. Depending on what is specified in that .sbatch file the slurm manager system allocates ressources for that job and runs it as soon there are resources ready. While training cycleGAN mode collapse happened and the test images didn't get translated at all. Also to train for the 200 recommended epochs it would take around 2-3 weeks due to training taking a day for around 14 epochs. This is probably due to the fact that training cycleGAN is only possible on batches of size 1 which makes the vast resources available on the cluster not usable to their full potential. Also the student account can only run one job at once which makes it impossible to train different methods (cycleGAN, CyCADA, GradGAN) at the same time. Another issue is that it was not possible to visualize loss of generators and discriminators in order to supervise the training process and check if mode collapse or any other issue appeared. 

\section{Datasets}

\subsection{Synthetic dataset: \\
	Playing for Data: Ground Truth from Computer Games}

The GTA5 (Grand Theft Auto V) dataset is proposed in \cite{Richter_2016_ECCV}. It contains 24966 images taken from a street view in the game Grand Theft Auto V by Rockstar Games \cite{GTAV}. The images are provided with $1914 \times 1052$ pixels and are containing moving cars, objects, pedestrians, bikes, have changing lighting and weather conditions aswell as day and night scenes. For all of these images the authors provide label images that are compatible with those of the Cityscapes dataset \cite{Cordts_2016_CVPR}. Detouring, i.e. injecting a wrapper between the game and the graphics hardware to log function calls and reconstruct the 3D scene is used. This enables a faster labeling process as objects in a scene can be assigned an object ID through which the assigned label is propagated to other images containing this same object. Due to being more realistic than other existing synthetic street view datasets (e.g. SYNTHIA \cite{RosCVPR16}) the GTAV dataset is very popular for training machine learning models related to autonomous driving and is therefore used in this work.


\subsection{Real dataset:\\
	The Cityscapes Dataset for Semantic Urban Scene Understanding}

The Cityscapes dataset \cite{Cordts_2016_CVPR} is a large scale dataset containing car dashcam view images from 50 european cities. It includes 30 classes relevant for autonomous driving. The images include scenes in spring, summer and fall seasons and under different weather conditions. There are 5000 images provided together with fine annotations and 20000 together with coarse annotations. Due to the large amount of labeled data from a dashvam view and the inclusion of scenes with different weather and lighting conditions this dataset is often used to train deep neural networks that are related to autonomous driving. Due to the popularity and the GTAV dataset containing compatible labeling maps, this work uses Cityscapes as the real dataset for the experiments.

\section{comparison Benchmark}
\subsection{Intersection over Union (IoU)}
The Intersection over Union is a metric often used to compare semantic segmentation methods. All of the compared techniques were evaluated using IoU. It follows the following formula:
\begin{align*}
	\frac{\text{predicted Pixels} \cap \text{ground truth Pixels}}{\text{predicted Pixels} \cup \text{ground truth Pixels}}
\end{align*}
where predicted Pixels are the pixels predicted for a specific class by the semantic segmentation model and ground truth Pixels are the Pixels containing the ground truth for that image. Usually there are multiple different classes to predict and therefore it is common to calculate the mean IoU (mIoU) over all images that have predictions. To compare how well classes themselves are predicted by a model, one can also calculate the class IoU (cIoU).

\subsection{Methodology}
For the comparison each technique was used to translate a sample of 500 images from the GTA dataset to the Cityscapes domain. For CycleGAN and SG-GAN each, the authors provided pre-trained models. For CyCADA pretranslated images are provided in the project repository \cite{CyCADA}. Due to CyCADA only providing 22k translated images instead of the full 25k images provided in the GTA dataset, from the randomly chosen 500 images only 450 are available here. This has to be regarded in the following comparison. To translate images with SG-GAN and CycleGAN the provided code \cite{SG},\cite{Cycle} and for the semantic segmentation task an implementation \cite{DLR} of deeplabv3 \cite{DBLP:journals/corr/ChenPSA17} was used. To compute the IoU values the deeplabv3 implementation uses the benchmark code provided by Cityscapes \cite{CSR}. All computations were run on Ubuntu 18.04 using CPU only in VirtualBox on a Windows Machine due to problems with dependencies while running the code on the tcml cluster of the university of tuebingen \cite{tcml}, a cluster for machine learning applications.
