\chapter{Foundations}
\label{sec:foundations}

This chapter will show and explain the foundations necessary for this work. The term \textbf{Domain Adaptation} aswell as what \textbf{synthetic} and \textbf{real} is referred to in the context of this work, will be defined and some examples shown. Furthermore the relevant Neural Network architecture \textbf{Generative Adversarial Networks} (GAN) will be described in detail.


\section{Domain Adaptation}
Collecting labeled data in the real world is expensive aswell as potentially inaccurate due to pixel level annotations being challenging for human annotators to do in a very detailed way. This is in contrast to synthetic data for which data collection and annotation can be highly automated. Examples for such synthetically generated datasets are the GTA dataset \cite{Richter_2016_ECCV} and the SYNTHIA dataset \cite{RosCVPR16}. The synthetic domain is different than the real domain (e.g. changes in texture, lighting, ...) though, which makes models trained on the synthetic data perform worse when applied in the real world. The research field of Domain Adaptation tackles this problem. As described in \cite{DBLP:journals/corr/Csurka17},
Domain Adaptation is the task of transfering a machine learning model that is working well on a source data distribution to a related target data distribution. This work focuses on the adaptation from synthetic-to-real images. Where synthetic images are images rendered from a virtual scene through a rendering engine like blender's ''Cycles`` \cite{Cycles} or graphics engine like Unity \cite{Unity}. While real images are defined as taken from a real-world scene through some kind of camera. See Figure \ref{fig:DA_examples} for an example of synthetic and real images. Other examples of domains are an image of a painting in the style of a particular artist, images of an object from different viewpoints. A major challenge in synthetic-to-real Domain Adaptation is that there is generally no paired data (in contrast to works like \cite{DBLP:journals/corr/IsolaZZE16} that work with domains that allow the use of paired data). Therefore synthetic-to-real Domain Adaptation methods have to be able to work with unpaired data. 

\begin{figure}
	\centering
	 \includegraphics[width=0.8\textwidth]{../images/DA_examples_cityscapes_gta.png}
	\caption{Example images for the the two domains relevant for this work. A real image from the Cityscapes dataset \cite{Cordts_2016_CVPR} (left) and a synthetic image from the GTA5 dataset \cite{Richter_2016_ECCV} (right)}
	\label{fig:DA_examples}
\end{figure}

\subsection{Example Applications}
\subsubsection{Semantic Segmentation}
Semantic Segmentation is one of the most important aspects in autonomous driving. It is the task of semantically segmentating objects in an image, i.e. labeling each pixel according to what object it belongs to. See Figure \ref{fig:semseg} for examples. Adapting semantic segmentation models is one application of Domain Adaptation and the one focused on in this work. 

\subsubsection{Classification}
Classification models or data that is fed into a classification model can also be adapted through Domain Adaptation. For example when adapting a model trained on classification of objects in pictures taken from a frontal view of that object to pictures taken from a side view (e.g. in \cite{10.1007/978-3-642-15561-1_16})

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{../images/semseg.png}
	\caption{Examples of semantic segmentation images. Image taken from the GTA5 dataset \cite{Richter_2016_ECCV} (left) and the same image mapped to Cityscapes Id values (pixel values 0-19, adapted to brighter values to improve visibility). Streets in purple, sidewalks in pink, pedestrians red, cars blue in the left image which is mainly for visualization purposes. The right image is used for processing.}
	\label{fig:semseg}
\end{figure}



\section{Generative Adversarial Networks}
Generative Adversarial Networks (GANs) implement a two-player-game:\\
A \textbf{Discriminator} learns from a given data distribution what is ``real''. The \textbf{Generator} generates data. The goal of the generator is to fool the discriminator into believing the generated data is ``real'' i.e. tries to create samples coming from the same distribution as the ``real'' data. The discriminator will label anything as ``fake'' that doesn't resemble the learned ``real'' data distribution. This can be described as a 2 classes classification, with classes real and fake or 1 and 0. This way GANs can learn to generate realistically looking images of faces, translate images of art from one style to another and improve semantic segmentation. The generative model generally uses \textit{maximum likelihood estimation}. In \cite{DBLP:journals/corr/Goodfellow17} it is described in the following way:
\begin{quote}
	The basic idea of maximum likelihood is to define a model that provides an estimate of probability distribution, parameterized by parameters $\theta$. We then refer to the \textbf{likelihood} as the probability that the model assigns to the training data: $\prod_{i=1}^{m}p_{\text{model}}(x^{(i)}; \theta)$
\end{quote}
The parameter $\theta$ that maximizes the likelihood of the data is better found in $\log$ space
\begin{align}
	\theta^* &= \underset{\theta}{\arg \max} \prod_{i = 1}^{m} p_{\text{model}} (x^{(i)}; \theta)\\
	&= \underset{\theta}{\arg \max} \log \prod_{i=1}^{m} p_{\text{model}}(x^{(i)}; \theta)\\
	&= \underset{\theta}{\arg \max} \sum_{i = 1}^{m} \log p_{\text{model}}(x^{(i)}; \theta)
\end{align}
as the maximum of the function is at the same $\theta$ value and the now obtained sum aswell eliminates the possibility of having underflow by multiplying multiple very small probabilities together. 
Formally GANs are a structured probabilistic model containing latent variables $\mathbf{z}$ and observed variables $\mathbf{x}$.
The generator is defined by a function G with input $\mathbf{z}$ and $\theta^{(G)}$ as parameters, the discriminator by a function D with input $\mathbf{x}$ and $\theta^{(D)}$ as parameters. The discriminator tries to minimize its cost function $J^{(D)}(\theta^{(D)}, \theta^{(G)})$ while only controlling $\theta^{(D)}$. This is analogous for the generator: he tries to minimize $J^{(G)}(\theta^{(D)}, \theta^{(G)})$ while controlling only $\theta^{(G)}$. In contrast to an optimization problem that has a solution that is the (local) minimum (a point in parameter space where all neighboring points have greater or equal cost), the GAN objective is a game. The solution to a game is a Nash equilibrium \cite{Nash48}, meaning that each player chooses the best possible option or strategy in respect to what the other player(s) choose. For GANs the Nash equilibrium is a tuple $(\theta^{(D)}, \theta^{(G)})$ that is a local minimum of $J^{(D)}$ with respect to $\theta^{(D)}$ and a local minimum $J^{(G)}$ with respect to $\theta^{(G)}$.
The generator is a differentiable function G. When inputting a random noise sample $\mathbf{z}$ to the generator, G(z) yields a sample of $\mathbf{x}$ drawn from $p_{\text{model}}$. Typically a deep neural network is used to represent G. \\
The game plays out in two scenarios. The first is where the discriminator D is given random training examples $\mathbf{x}$ from the training set. The goal of the discriminator here is for $D(\mathbf{x})$ to be near 1. In the second scenario, random noise $\mathbf{z}$ is input to the generator. The discriminator then receives input $G(\mathbf{z})$, a fake sample by the generator. The discriminator strives to make $D(G(\mathbf{z}))$ approach 0 while the generator tries to make that same value approach 1. The game's Nash equilibrium corresponds to the generators output $G(\mathbf{z})$ being drawn from the same distribution as the training data. Under the assumption that the inputs to the discriminator are half real and half fake, this corresponds to $D(\mathbf{x}) = \frac{1}{2}$ for all $\mathbf{x}$.

\paragraph{Training}
On each step, two minibatches are sampled: a minibatch of $\mathbf{x}$ values from the dataset and one of random noise $\mathbf{z}$. Then two gradient steps are made simultaneously (simultaneous stochastic gradient descent): one updating $\theta^{(D)}$ to reduce $J^{(D)}$ and one updating $\theta^{(G)}$ to reduce $J^{(G)}$.

\paragraph{Loss functions} There are many different loss functions that can be used for GANs. See chapter \ref{sec:techniques} for the ones that the techniques in this work use.


\todo{restructure this or delete generator and discriminator subsections}
\subsection{The Generator}

\subsection{The Discriminator}

\subsection{Conditional GANs}
Instead of having random noise as input to the Net, conditional GANs get a conditional input that determines the output. \cite{DBLP:journals/corr/IsolaZZE16} generated images of shoes depending on drawn sketches thereof, translated grayscale images to color images and more (See Figure \ref{fig:I2I_examples} for examples). This is the same for the methods compared in this work: They use a synthetic image as conditional input and generate an image that looks more realistic while preserving features and image elements of the original image.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{../images/I2I_examples.png}
	\caption{Examples of conditional inputs and generated images (output) of conditional GANs as described in \cite{DBLP:journals/corr/IsolaZZE16}}
	\label{fig:I2I_examples}
\end{figure}


\subsection{Training}
There are many different approaches on training GANs. Training details of the Techniques that this work focuses on can be found in Section \ref{sec:techniques}.


\subsection{Advantages and Disadvantages}
\paragraph{Disadvantages}
\paragraph{non-convergence.} Mentioned in \cite{DBLP:journals/corr/Goodfellow17} as ``The largest problem facing GANs [...]'': When training GANs, while updating one player so that he makes the best possible current move and goes downhill the loss curve it is possible that the counterfeit player gets updated into going uphill the loss curve. This is in contrast to optimization problems where one tries to find a (local) minimum of the loss curve for example through stochastic gradient decent (SGD). Because there is only one gradient instead of the two in GAN objectives, the model generally makes reliable downhill progress during training. The result is that GANs often oscillate in practice due to the nature of having two players playing against each other, each trying to achieve the optimal outcome for themselves. 

\paragraph{mode collapse} occurs when the generator learns to map different inputs to the same output. This results in generated data that is missing diversity. A solution is proposed in \cite{DBLP:journals/corr/ZhuPIE17}: Using a batch history of 50 images so that the discriminator also learns the distribution of images of the training data and can therefore make sure that the generator will not generate the same small set of images. Partial mode collapse refers to scenarios in which the generator makes multiple images containing the same color or texture themes, or multiple images containing different views of the same dog. See Figure \ref{fig:mode_collapse} for an example.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{images/metz_et_al_mode_collapse.png}
	\caption{Mode collapse example: Target data distribution of a toy dataset (right) and the data distribution of generated samples. Mind that the generated sample distribution hops from one mode to the next as the discriminator learns to recognize each mode as fake. Image from \cite{DBLP:journals/corr/MetzPPS16}}
	\label{fig:mode_collapse}
\end{figure}

\newpage

\paragraph{Advantages} (As described in \cite{GAN_Projects})
\paragraph{unsupervised.} GANs are trained in an unsupervised manner. There is no ground truth (i.e. labeled data) or an external true or false feedback (reinforcement learning) necessary to train the network. This makes acquiring data cheaper and easier and therefore training of GANs aswell. 

\paragraph{data generation.} GANs learn to generate data that is indistinguishable from real data. This is useful for many applications such as generating images that can be used by artists to quickly generate a few samples of an idea, generate text that can then be adjusted to a specific purpose, aswell as generating audio and video.

\paragraph{learn density distribution.} GANs learn a density distribution of given data. In contrast to other models that can only learn specific distributions, GANs can learn different diverse and complex data distributions.

\paragraph{discriminator is a classifier.} The trained discriminator of GANs is a binary classifier and can be used as such. For example if the discriminator learns that images from real data contain a dog it can be used to classify if an image contains a dog or not. 