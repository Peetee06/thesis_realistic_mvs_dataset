\chapter{Related Work}
\label{sec:related_work}
There are many different approaches on Domain Adaptation for even more diverse tasks. This chapter will show a possible categorization framework for them while giving example techniques each.

\section{A Categorization of Domain Adaptation techniques}
Domain Adaptation can be subcategorized and defined according to \cite{DBLP:journals/corr/Csurka17}. The following subsections specify these subcategories, will give a definition as stated in \cite{DBLP:journals/corr/abs-1802-03601} and example works each.

\subsection{Discrepancy based}
Discrepancy based techniques try to adapt domains by fine-tuning the deep network with labeled or unlabeled target data. They can further be subdivided in following categories:

\paragraph{Class Criterion.}
Uses the class label information to transfer knowledge between domains. Approaches that are commonly used when labeled target data is available are soft label and metric learning. An example for this is \cite{DBLP:journals/corr/TzengHDS15}. The authors accomplish domain adaptation by computing an estimated marginal distribution over the target domain using some labeled target data and optimize the network to minimize the distance between source and target domain distributions. If no labeled target data is available, pseudo labels and attribute representation among others are possible approaches. \cite{DBLP:journals/corr/ZhangYCW15} propose the Deep Transfer Network (DTN) which models and matches both the marginal and the conditional distributions of source and target domains. Pseudo labels are used here in order to compute the distance between conditional distributions of the source and target domain using a conditional Maximum Mean Discrepancy (MMD). An example for synthetic-to-real domain adaptation is \cite{DBLP:journals/corr/LopezXGVR16} where the authors use some of these approaches to train a deformable part-based model (DPM) on the synthetic-to-real domain adaptation task between the SYNTHIA \cite{RosCVPR16} and Cityscapes \cite{Cordts_2016_CVPR} datasets.


\paragraph{Statistic Criterion.}
Uses mechanisms like MMD as used in \cite{DBLP:journals/corr/ZhangYCW15} and correlation alignment (CORAL) among others to align the statistical distribution shift between the source and target domains. CORAL as proposed in \cite{DBLP:journals/corr/SunFS15} aligns the second-order statistics of source and target data distributions through a linear transformation. \cite{DBLP:journals/corr/SunS16a} extend this to use with deep neural networks. The authors construct the CORAL loss ``by constructing a differentiable loss function that minimizes the difference between source and target correlations''. They show that their proposed technique can be applied to more diverse problems than the original CORAL because it learns a non-linear transformation.

\paragraph{Architecture Criterion.}
The network is modified in order to make it able to learn more transferable features. A prominent technique is batch normalization (BN) as propsed in \cite{DBLP:journals/corr/IoffeS15} where a layer is added to the network in order to reduce internal covariate shift.  Further techniques include weak-related weight, domain-guided dropout and others. %\todo{Effective Use of Synthetic Data..., Exemplar Guided...}

\paragraph{Geometric Criterion.}
Assumes that the relationship of geometric structures in source and target domain can reduce the domain shift and bridges these domains according to their geometrical properties. \cite{Chopra2013DLIDDL} uses this assumption to define a so called ``interpolating path'' between the source and target domains which they use in order to adapt their model.

\subsection{Adversarial based}
Uses a discriminator as described in Chapter \ref{sec:foundations} to distinguish between samples from source and target domain. With it an adversarial objective to minimize the distance between empirical source and target mapping distributions is used to encourage domain confusion. Adversarial based techniques can be further subcategorized according to if generative models are used or not.

\paragraph{Generative models.}
Mainly GANs as described in Chapter \ref{sec:foundations}. The techniques compared in this work are all GAN-based and will be explained in more detail in Chapter \ref{sec:techniques}.

\paragraph{Non-generative models.}
The feature extractor learns a discriminative representation using the labels of the source domain and maps the target to the same space through a domain-confusion loss, thus resulting in domain-invariant representations. \cite{DBLP:journals/corr/HoffmanWYD16} propose ``the first unsupervised domain adaptation method for transferring semantic segmentation FCNs [(Fully Convolutional Networks)] across image domains''. The authors techniques maps the source and target domain features to a common label space using an adversarial learning procedure that learns to distinguish between the two domains in order to guide the distance minimization of the two domains' representations. 

\subsection{Reconstruction based}
Assumes that the data reconstruction of source and target data can be helpful for improving the performance of DA. The reconstructor can ensure both specificity of intra-domain representations and indistinguishability of inter-domain representations.

\paragraph{Encoder-Decoder Reconstruction.}
Encoder-decoder techniques use stacked autoencoders (SAEs) to combine the encoder network for representation learning with a decoder network for data reconstruction. \cite{DBLP:journals/corr/GhifaryKZBL16} propose the Deep Reconstruction-Classification Network (DRCN). This technique learns to predict labels on source domain images in a supervised way and reconstruct target data in an unsupervised way. The goal is to correctly label images in the target domain supported by the auxiliary task of data reconstruction. 

\paragraph{Adversarial Reconstruction.}
Includes techniques that use a reconstruction error such as the cycle-consistency loss in CycleGAN (see Chapter \ref{sec:techniques} for more details) which measures the distance between the original and reconstructed images within each domain.